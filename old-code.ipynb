{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b186d131",
   "metadata": {},
   "outputs": [],
   "source": [
    "#deal with tensors\n",
    "import torch   \n",
    "import torch.nn as nn\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#handling text data\n",
    "from torchtext.legacy import data\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "229d6357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Data\n",
    "\n",
    "test = pd.read_json(\"./minidata/trainDATASET.json\", lines=True)\n",
    "train = pd.read_json(\"./minidata/trainDATASET.json\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c87d23b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shape of dataset\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08b5d8a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eBay O*14-xxxxx-03975 - Visa Purchase - Receip...</td>\n",
       "      <td>random</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ROLLD KOTARA - Visa Purchase - Receipt ${recei...</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amazon Australia Services - Visa Purchase - Re...</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AMAZON MKTPLC AU - Visa Purchase - Receipt ${r...</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description     tag\n",
       "0  eBay O*14-xxxxx-03975 - Visa Purchase - Receip...  random\n",
       "1  ROLLD KOTARA - Visa Purchase - Receipt ${recei...    food\n",
       "2  Amazon Australia Services - Visa Purchase - Re...   other\n",
       "3  AMAZON MKTPLC AU - Visa Purchase - Receipt ${r...   other"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d4acaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to clean data\n",
    "def normalise_text (text):\n",
    "    text = text.str.lower() # lowercase\n",
    "    text = text.str.replace(r\"\\#\",\"\") # replaces hashtags\n",
    "    text = text.str.replace(r\"http\\S+\",\"URL\")  # remove URL addresses\n",
    "    text = text.str.replace(r\"@\",\"\")\n",
    "    text = text.str.replace(r\"[^A-Za-z0-9()!?\\'\\`\\\"]\", \" \")\n",
    "    text = text.str.replace(\"\\s{2,}\", \" \")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0878a0f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Moosa\\anaconda3\\envs\\myenv\\lib\\site-packages\\ipykernel_launcher.py:4: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\Moosa\\anaconda3\\envs\\myenv\\lib\\site-packages\\ipykernel_launcher.py:5: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  \"\"\"\n",
      "C:\\Users\\Moosa\\anaconda3\\envs\\myenv\\lib\\site-packages\\ipykernel_launcher.py:7: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  import sys\n",
      "C:\\Users\\Moosa\\anaconda3\\envs\\myenv\\lib\\site-packages\\ipykernel_launcher.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "train[\"description\"]=normalise_text(train[\"description\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "174d69b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    ebay o 14 xxxxx 03975 visa purchase receipt re...\n",
       "1    rolld kotara visa purchase receipt receipt no ...\n",
       "2    amazon australia services visa purchase receip...\n",
       "3    amazon mktplc au visa purchase receipt receipt...\n",
       "Name: description, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['description'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec99034a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train and validation \n",
    "train_df, valid_df = train_test_split(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbfaf412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rolld kotara visa purchase receipt receipt no ...</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ebay o 14 xxxxx 03975 visa purchase receipt re...</td>\n",
       "      <td>random</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>amazon australia services visa purchase receip...</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description     tag\n",
       "1  rolld kotara visa purchase receipt receipt no ...    food\n",
       "0  ebay o 14 xxxxx 03975 visa purchase receipt re...  random\n",
       "2  amazon australia services visa purchase receip...   other"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc5cf039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>amazon mktplc au visa purchase receipt receipt...</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description    tag\n",
       "3  amazon mktplc au visa purchase receipt receipt...  other"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44a4e41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7785801",
   "metadata": {},
   "outputs": [],
   "source": [
    "DESCRIPTION = data.Field(tokenize = 'spacy', include_lengths = True)\n",
    "TAG = data.LabelField(dtype = torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b76728b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary representing the dataset\n",
    "fields = {\n",
    "  'description': ('description', DESCRIPTION),\n",
    "  'tag': ('tag', TAG)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "22ab0067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset in json format\n",
    "train_ds, test_ds = data.TabularDataset.splits(\n",
    "  path = 'mydata',\n",
    "  train = 'smaller-dataset.json',\n",
    "  test = 'modified-smaller-dataset.json',\n",
    "  format = 'json',\n",
    "  fields = fields\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46fd977c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'description': ['AMAZON', 'MKTPLC', 'AU', '-', 'Visa', 'Purchase', '-', 'Receipt', '$', '{', 'receipt_no', '}', 'SYDNEY', 'SOUTH', 'trans_date', '}', '2022', 'Card', '491684xxxxxx8665'], 'tag': 'other'}\n",
      "<class 'torchtext.legacy.data.example.Example'>\n"
     ]
    }
   ],
   "source": [
    "# Lets look at a random example\n",
    "print(vars(train_ds[1]))\n",
    "\n",
    "# Check the type \n",
    "print(type(train_ds[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fb727356",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_VOCAB_SIZE = 25000\n",
    "\n",
    "DESCRIPTION.build_vocab(train_ds, \n",
    "                 max_size = MAX_VOCAB_SIZE, \n",
    "                 vectors = 'glove.6B.200d',\n",
    "                 unk_init = torch.Tensor.zero_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aef27453",
   "metadata": {},
   "outputs": [],
   "source": [
    "TAG.build_vocab(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f82af615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[14, 16],\n",
      "        [20, 17],\n",
      "        [15, 23],\n",
      "        [ 2,  2],\n",
      "        [10, 10],\n",
      "        [ 8,  8],\n",
      "        [ 2,  2],\n",
      "        [ 9,  9],\n",
      "        [ 4,  4],\n",
      "        [ 5,  5],\n",
      "        [11, 11],\n",
      "        [ 3,  3],\n",
      "        [22, 19],\n",
      "        [21, 18],\n",
      "        [12,  4],\n",
      "        [ 3,  5],\n",
      "        [13, 12],\n",
      "        [ 7,  3],\n",
      "        [ 6,  7],\n",
      "        [ 1,  6]]), tensor([19, 20]))\n",
      "tensor([0., 0.])\n"
     ]
    }
   ],
   "source": [
    "#check whether cuda is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  \n",
    "\n",
    "#set batch size\n",
    "BATCH_SIZE = 2\n",
    "\n",
    "#Load an iterator\n",
    "train_iterator, valid_iterator = data.BucketIterator.splits(\n",
    "    (train_ds, test_ds), \n",
    "    batch_size = BATCH_SIZE,\n",
    "    sort_key=lambda x: len(x.tag),\n",
    "    sort=False,\n",
    "    sort_within_batch=True,\n",
    "    device = device)\n",
    "\n",
    "for batch in train_iterator:\n",
    "    print(batch.description)\n",
    "    print(batch.tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e4e1ea6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "num_epochs = 25\n",
    "learning_rate = 0.001\n",
    "\n",
    "INPUT_DIM = len(DESCRIPTION.vocab)\n",
    "EMBEDDING_DIM = 200\n",
    "HIDDEN_DIM = 256\n",
    "OUTPUT_DIM = 1\n",
    "N_LAYERS = 2\n",
    "BIDIRECTIONAL = True\n",
    "DROPOUT = 0.2\n",
    "PAD_IDX = DESCRIPTION.vocab.stoi[DESCRIPTION.pad_token] # padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "38a8836e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_net(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, \n",
    "                 bidirectional, dropout, pad_idx):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n",
    "        \n",
    "        self.rnn = nn.LSTM(embedding_dim, \n",
    "                           hidden_dim, \n",
    "                           num_layers=n_layers, \n",
    "                           bidirectional=bidirectional, \n",
    "                           dropout=dropout)\n",
    "        \n",
    "        self.fc1 = nn.Linear(hidden_dim * 2, hidden_dim)\n",
    "        \n",
    "        self.fc2 = nn.Linear(hidden_dim, 1)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, text, text_lengths):\n",
    "        \n",
    "        # text = [sent len, batch size]\n",
    "        \n",
    "        embedded = self.embedding(text)\n",
    "        \n",
    "        # embedded = [sent len, batch size, emb dim]\n",
    "        \n",
    "        #pack sequence\n",
    "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths, enforce_sorted=False)\n",
    "        \n",
    "        packed_output, (hidden, cell) = self.rnn(packed_embedded)\n",
    "        \n",
    "        #unpack sequence\n",
    "        # output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output)\n",
    "\n",
    "        # output = [sent len, batch size, hid dim * num directions]\n",
    "        # output over padding tokens are zero tensors\n",
    "        \n",
    "        # hidden = [num layers * num directions, batch size, hid dim]\n",
    "        # cell = [num layers * num directions, batch size, hid dim]\n",
    "        \n",
    "        # concat the final forward (hidden[-2,:,:]) and backward (hidden[-1,:,:]) hidden layers\n",
    "        # and apply dropout\n",
    "        \n",
    "        hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n",
    "        output = self.fc1(hidden)\n",
    "        output = self.dropout(self.fc2(output))\n",
    "                \n",
    "        #hidden = [batch size, hid dim * num directions]\n",
    "            \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e1c424e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating instance of our LSTM_net class\n",
    "\n",
    "model = LSTM_net(INPUT_DIM, \n",
    "            EMBEDDING_DIM, \n",
    "            HIDDEN_DIM, \n",
    "            OUTPUT_DIM, \n",
    "            N_LAYERS, \n",
    "            BIDIRECTIONAL, \n",
    "            DROPOUT, \n",
    "            PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "15ad3bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([24, 200])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [-0.5248, -0.3196, -0.1190,  ..., -0.0464,  0.5881,  1.5755],\n",
       "        ...,\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_embeddings = DESCRIPTION.vocab.vectors\n",
    "\n",
    "print(pretrained_embeddings.shape)\n",
    "model.embedding.weight.data.copy_(pretrained_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "73521e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.5248, -0.3196, -0.1190,  ..., -0.0464,  0.5881,  1.5755],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]])\n"
     ]
    }
   ],
   "source": [
    "#  to initiaise padded to zeros\n",
    "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "\n",
    "print(model.embedding.weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ed887b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device) #CNN to GPU\n",
    "\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e43fb158",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float() #convert into float for division \n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "77f8eb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training function \n",
    "def train(model, iterator):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        text, text_lengths = batch.description\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(text, text_lengths).squeeze(1)\n",
    "        loss = criterion(predictions, batch.tag)\n",
    "        acc = binary_accuracy(predictions, batch.tag)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1663c10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator):\n",
    "    \n",
    "    epoch_acc = 0\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            text, text_lengths = batch.text\n",
    "            predictions = model(text, text_lengths).squeeze(1)\n",
    "            acc = binary_accuracy(predictions, batch.tag)\n",
    "            \n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8303ba25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# t = time.time()\n",
    "# loss=[]\n",
    "# acc=[]\n",
    "# val_acc=[]\n",
    "# \n",
    "# for epoch in range(num_epochs):\n",
    "#     \n",
    "#     train_loss, train_acc = train(model, train_iterator)\n",
    "#     valid_acc = evaluate(model, valid_iterator)\n",
    "#     \n",
    "#     print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "#     print(f'\\t Val. Acc: {valid_acc*100:.2f}%')\n",
    "#     \n",
    "#     loss.append(train_loss)\n",
    "#     acc.append(train_acc)\n",
    "#     val_acc.append(valid_acc)\n",
    "#     \n",
    "# print(f'time:{time.time()-t:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "97e32069",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AmazonLSTMRNN(nn.Module):\n",
    "  def __init__(self, vocab_size, embedding_size, hidden_size, output_size, num_layers\n",
    "               , bidirectional, dropout, pad_idx):\n",
    "    super(AmazonLSTMRNN, self).__init__()\n",
    "\n",
    "    self.embedding = nn.Embedding(vocab_size, embedding_dim=embedding_size, padding_idx=pad_idx)\n",
    "    self.lstm = nn.LSTM(embedding_size, hidden_size=hidden_size, \n",
    "                        bidirectional=bidirectional, num_layers=num_layers,\n",
    "                        dropout=dropout)\n",
    "    self.fc = nn.Linear(hidden_size * 2, out_features=output_size)\n",
    "    self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "  def forward(self, text, text_lengths):\n",
    "    embedded = self.dropout(self.embedding(text))\n",
    "    packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths.to('cpu'), enforce_sorted=False)\n",
    "    packed_output, (h_0, c_0) = self.rnn(packed_embedded)\n",
    "    output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output)\n",
    "    h_0 = self.dropout(torch.cat((h_0[-2,:,:], h_0[-1,:,:]), dim = 1))\n",
    "    return self.fc(h_0)\n",
    "\n",
    "\n",
    "INPUT_DIM = len(DESCRIPTION.vocab) # # 25002\n",
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 256\n",
    "OUTPUT_DIM = 1\n",
    "N_LAYERS = 2\n",
    "BIDIRECTIONAL = True\n",
    "DROPOUT = 0.5\n",
    "PAD_IDX = DESCRIPTION.vocab.stoi[DESCRIPTION.pad_token] # 0\n",
    "amazon_model = AmazonLSTMRNN(INPUT_DIM, \n",
    "            EMBEDDING_DIM, \n",
    "            HIDDEN_DIM, \n",
    "            OUTPUT_DIM, \n",
    "            N_LAYERS, \n",
    "            BIDIRECTIONAL, \n",
    "            DROPOUT, \n",
    "            PAD_IDX)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(amazon_model.parameters())\n",
    "amazon_model = amazon_model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f5dd5418",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    model.train()\n",
    "    for batch in iterator:\n",
    "        optimizer.zero_grad()\n",
    "        text, text_lengths = batch.description\n",
    "        predictions = model(text, text_lengths).squeeze(1)\n",
    "        loss = criterion(predictions, batch.tag)\n",
    "        acc = binary_accuracy(predictions, batch.tag)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "97ff8041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.753 | Train Acc: 0.00%\n",
      "\tTrain Loss: 0.723 | Train Acc: 50.00%\n",
      "\tTrain Loss: 0.693 | Train Acc: 100.00%\n",
      "\tTrain Loss: 0.693 | Train Acc: 100.00%\n",
      "\tTrain Loss: 0.757 | Train Acc: 0.00%\n",
      "time:0.410\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "acc=[]\n",
    "loss=[]\n",
    "N_EPOCHS = 5\n",
    "best_valid_loss = float('inf')\n",
    "valid_loss = 5000\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    start_time = time.time()\n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
    "    end_time = time.time()\n",
    "    #epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'best-model.pt')\n",
    "    #print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    \n",
    "    loss.append(train_loss)\n",
    "    acc.append(train_acc)\n",
    "    \n",
    "print(f'time:{time.time()-t:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d7bd318d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel(\"runs\")\n",
    "plt.ylabel(\"normalised measure of loss/accuracy\")\n",
    "x_len=list(range(len(acc)))\n",
    "plt.axis([0, max(x_len, default=0), 0, 1])\n",
    "plt.title('result of LSTM')\n",
    "loss=np.asarray(loss)/max(loss, default=0)\n",
    "plt.plot(x_len, loss, 'r.',label=\"loss\")\n",
    "plt.plot(x_len, acc, 'b.', label=\"accuracy\")\n",
    "#plt.plot(x_len, val_acc, 'g.', label=\"val_accuracy\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.2)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "af0961c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM_net(\n",
       "  (embedding): Embedding(24, 200, padding_idx=1)\n",
       "  (rnn): LSTM(200, 256, num_layers=2, dropout=0.2, bidirectional=True)\n",
       "  (fc1): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (fc2): Linear(in_features=256, out_features=1, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e76d2af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy \n",
    "nlp = spacy.load(\"en\")\n",
    "\n",
    "def predict(model, sentence):\n",
    "    tokenized = [tok.text for tok in nlp.tokenizer(sentence)]  #tokenize the sentence \n",
    "    indexed = [DESCRIPTION.vocab.stoi[t] for t in tokenized]   #convert to integer sequence\n",
    "    length = [len(indexed)]                                    #compute no. of words\n",
    "    tensor = torch.LongTensor(indexed).to(device)              #convert to tensor\n",
    "    tensor = tensor.unsqueeze(1).T                             #reshape in form of batch,no. of words\n",
    "    length_tensor = torch.LongTensor(length)                   #convert to tensor\n",
    "    prediction = model(tensor, length_tensor)                  #prediction \n",
    "    return prediction.item()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f072c23c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09075460582971573"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make predictions\n",
    "predict(model, \"ebay\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8d8a0f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "data = {\"model\": model, \"description\": DESCRIPTION}\n",
    "with open('saved_steps.pkl', 'wb') as file:\n",
    "    pickle.dump(data, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e3d591af",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('saved_steps.pkl', 'rb') as file:\n",
    "    data = pickle.load(file)\n",
    "\n",
    "model_loaded = data[\"model\"]\n",
    "DESCRIPTION = data[\"description\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8365a750",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09075460582971573"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = predict(model, \"ebay\")\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfda505",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
